# 测量的正确性

## 衡量标准

### 混淆矩阵（Confusion matrix

### 准确率(Accuracy)

$$
\frac{\Sigma T*}{\Sigma}
$$



### 精度/阳性预测值(Precision/PPV)

$$
\frac{TP}{\Sigma  P*}
$$



### 召回率/灵敏度/命中率/真阳性率(recall/sensitivity/true positive rate)

$$
\frac{11}{11+00}
$$



### F1分数（调和平均数）

精度和召回率的调和平均数

### 其他标准

## 一些值得注意的点

### 为什么只分析“某一个TP（真阳性）之类的指标”或者“计算判断错误的结果”这样的方案不好？

- 只分析TP的情景下，如果预测器全部做了positive的判断，那么TP是100%，但是对于False案例来说是灾难性的。在MP疾病案例中，这意味着所有没有疾病的病人都要切除拇指。
- “计算判断错误的结果”不能反映预测器错误的原因，如果我们想要改进预测器的表现，就需要去分析它的错误原因

### 错误分类是被允许的，但是会有代价权衡的问题

* 根据预测器的实际应用，为了降低成本，错误分类是被允许的，但是常常涉及FP和FN的代价权衡。比如，在生产线中，不可以出现某个已经被禁止的产品A。如果更新机器，就会影响整个生产线的运转，所以可以选择先生产产品，再挑选出A。那么这时候就可以允许不是A的产品被分类为A（假设被分类为A为POSITIVE, 那么生产线允许FN的错误），但是不允许A被分类为非A的产品(不允许FP)。

### 完美精度/召回率陷阱

* 单独看精度或者单独看召回率，都会使得一个很糟糕的分类器看起来表现很棒。需要结合二者，比如F1分数。F1分数是二者的调和平均数，只有在二者都很高的时候，F1才会很高。